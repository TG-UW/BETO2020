{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Associating a vector to each of the terms found in the carbon corpus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import sklearn\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "import Levenshtein as lev\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Carbon_SynAntList_Full_Refined_copy.xlsx', skip_rows=1)\n",
    "df = df.rename(columns = {'Carbon_SynAntList_Full_Refined':'index', 'Unnamed: 1':'word 1', 'Unnamed: 2':'word 2','Unnamed: 3':'relationship', 'Unnamed: 4': 'label'})\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev.distance('carbon','original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add Levenshtein distance, stem similarity, lemma similarity\n",
    "stems_equal = []\n",
    "lemmas_equal = []\n",
    "lev_distance = []\n",
    "for row in df.iterrows():\n",
    "    word1 = row[1]['word 1']\n",
    "    word2 = row[1]['word 2']\n",
    "    distance = lev.distance(str(word1), str(word2))\n",
    "    lev_distance.append(distance)\n",
    "    \n",
    "    word1_lemma = lemmatizer.lemmatize(str(word1))\n",
    "    word2_lemma = lemmatizer.lemmatize(str(word2))\n",
    "    lemmas_equal.append(word1_lemma==word2_lemma)\n",
    "    \n",
    "    word1_stem = stemmer.stem(str(word1))\n",
    "    word2_stem = stemmer.stem(str(word2))\n",
    "    stems_equal.append(word1_stem==word2_stem)\n",
    "\n",
    "df['lev_distance'] = lev_distance\n",
    "df['lemmas?'] = lemmas_equal\n",
    "df['stems?'] = stems_equal\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.iloc[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word 1</th>\n",
       "      <th>word 2</th>\n",
       "      <th>relationship</th>\n",
       "      <th>label</th>\n",
       "      <th>lev_distance</th>\n",
       "      <th>lemmas?</th>\n",
       "      <th>stems?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>carbon</td>\n",
       "      <td>original</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>carbon</td>\n",
       "      <td>graphite</td>\n",
       "      <td>syn</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>carbon</td>\n",
       "      <td>soot</td>\n",
       "      <td>syn</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>carbon</td>\n",
       "      <td>imitate</td>\n",
       "      <td>syn</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>infinite</td>\n",
       "      <td>ending</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1995.0</td>\n",
       "      <td>infinite</td>\n",
       "      <td>ephemeral</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1996.0</td>\n",
       "      <td>infinite</td>\n",
       "      <td>finite</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1997.0</td>\n",
       "      <td>infinite</td>\n",
       "      <td>intermittent</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1998.0</td>\n",
       "      <td>infinite</td>\n",
       "      <td>limited</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index    word 1        word 2 relationship label  lev_distance  \\\n",
       "0        0.0         0             1            2     0             1   \n",
       "1        0.0    carbon      original          ant     0             7   \n",
       "2        1.0    carbon      graphite          syn     1             7   \n",
       "3        2.0    carbon          soot          syn     1             5   \n",
       "4        3.0    carbon       imitate          syn     0             7   \n",
       "...      ...       ...           ...          ...   ...           ...   \n",
       "1995  1994.0  infinite        ending          ant     0             5   \n",
       "1996  1995.0  infinite     ephemeral          ant     0             9   \n",
       "1997  1996.0  infinite        finite          ant     0             2   \n",
       "1998  1997.0  infinite  intermittent          ant     0             7   \n",
       "1999  1998.0  infinite       limited          ant     0             5   \n",
       "\n",
       "      lemmas?  stems?  \n",
       "0       False   False  \n",
       "1       False   False  \n",
       "2       False   False  \n",
       "3       False   False  \n",
       "4       False   False  \n",
       "...       ...     ...  \n",
       "1995    False   False  \n",
       "1996    False   False  \n",
       "1997    False   False  \n",
       "1998    False   False  \n",
       "1999    False   False  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recording each individual word in the pairs\n",
    "words = []\n",
    "for i in range(len(df)):\n",
    "        if df.iloc[i,0] in words:\n",
    "            continue\n",
    "        else:\n",
    "            words.append(df.iloc[i,0])\n",
    "        \n",
    "        if df.iloc[i,1] in words:\n",
    "            continue\n",
    "        else:\n",
    "            words.append(df.iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have list of list of words\n",
    "def listoflist(lst):\n",
    "    return[[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = listoflist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training w2v model to get vectors for each word\n",
    "model = Word2Vec(words, size=100, min_count=1, iter=30) #training model with token list from above\n",
    "vocabulary = list(model.wv.vocab) #saving vocabulary as list for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the vector associated with a word in the vocabulary\n",
    "model.wv.__getitem__('current')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the syn subspace\n",
    "#sigmoidal activation\n",
    "class syn_subspace(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_reprs, out_reprs=60): #60 is the dimensionality of the syn subspace\n",
    "        \n",
    "        self.in_reprs = in_reprs #net knows that in_reprs is the value that is passed through me\n",
    "        self.out_reprs = out_reprs \n",
    "    \n",
    "        self.layers = []\n",
    "        self.layers.append(nn.Linear(self.in_reprs, self.out_reprs))\n",
    "        \n",
    "        self.layers = nn.Sequential(*self.layers) #turn your layers list into an object you can pass tensors through\n",
    "        \n",
    "    def forward(self, x): #x is the tensor that we send through\n",
    "        \n",
    "        out = self.layers(x)\n",
    "    \n",
    "    return out\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the ant subspace\n",
    "class ant_subspace(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_reprs, out_reprs=60): #60 is the dimensionality of the ant subspace\n",
    "        \n",
    "        self.in_reprs = in_reprs #net knows that in_reprs is the value that is passed through it\n",
    "        self.out_reprs = out_reprs \n",
    "    \n",
    "        self.layers = []\n",
    "        self.layers.append(nn.Linear(self.in_reprs, self.out_reprs))\n",
    "        \n",
    "        self.layers = nn.Sequential(*self.layers) #turn your layers list into an object you can pass tensors through\n",
    "        \n",
    "    def forward(self, x): #x is the tensor that we send through\n",
    "        \n",
    "        out = self.layers(x)\n",
    "        \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating master layer\n",
    "class FullNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_reprs, out_reprs)\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    in_reprs(torch.tensor): the dimensionality of the concacenated input data from w2v, stem, lemma, Lev.\n",
    "    out_reprs: the dimensionality of what we want for the whole NN\n",
    "    \n",
    "    \"\"\"\n",
    "        self.in_reprs = in_reprs #representation of w2v+ encodings\n",
    "        self.out_reprs = out_reprs #representation that will be fed to create both subspaces\n",
    "    \n",
    "        self.layers = []\n",
    "        self.layers.append(nn.Linear(self.in_reprs, self.out_reprs), nn.)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
