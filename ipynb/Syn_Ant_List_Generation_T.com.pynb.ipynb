{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to create list of synonyms and antonyms from words found on Thesaurus.com and Word.net\n",
    "#First thought is to create a list of words of interest that can be queried directly by our script \n",
    "#Need to also create a list of list of the words that we used to create the syn-ant query list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Thesaurus.com (T.com)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_words = ['corrosion', 'flammable', 'resistant', 'retardate', 'malleable']\n",
    "syn_list = []\n",
    "ant_list = []\n",
    "\n",
    "start = time.time() #To determine scalability. Times are inconsistent.\n",
    "\n",
    "for word in useful_words: #pull words from a premade list to query T.com\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get('https://www.thesaurus.com/browse/' + word)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    html_doc = driver.page_source # stores the source HTML code in the driver's page_source attribute\n",
    "   \n",
    "    #Issue with next two lines is that we are also picking up \"Related Terms\" synonyms and antonyms.\n",
    "    #Dirty fix is to keep only the 5 ant and syn results from a query after it has been cleaned.\n",
    "    syn = re.findall(r'\"similarity\":\"100\",\"isInformal\":\"0\",\"isVulgar\":null,\"term\":\"(\\S*?)\",\"targetTerm\"', html_doc) \n",
    "    ant = re.findall(r'\"similarity\":\"-100\",\"isInformal\":\"0\",\"isVulgar\":null,\"term\":\"(\\S*?)\",\"targetTerm\"', html_doc)\n",
    "    \n",
    "    syn_list.append(syn)\n",
    "    ant_list.append(ant)\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)\n",
    "    #To retrieve \"Related Terms\" from a query to add to list\n",
    "    #\"entry\":\"corrosion\",\"targetTerm\":\"canker\",\"targetSlug\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame creation based off amount of 'useful_words'\n",
    "test_array = np.empty((len(useful_words),3))\n",
    "test_array_df = pd.DataFrame(data=test_array[0:,:], columns = {'Term', 'Synonyms', 'Antonyms'})\n",
    "\n",
    "#Creation of raw list of lists of syn/ant for each 'useful_word'\n",
    "raw_syn_list = [[] for i in range(len(useful_words))]\n",
    "raw_ant_list = [[] for i in range(len(useful_words))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up scraped data (remove repetitions, need to find out how many syn/ant we want to keep)\n",
    "#Populate raw list of lists with cleaned syn/ant for each'useful_word'\n",
    "for i in range(len(useful_words)):\n",
    "    for word in syn_list[i]:\n",
    "        if word in raw_syn_list[i]:\n",
    "            continue\n",
    "        else:\n",
    "            raw_syn_list[i].append(word)\n",
    "    \n",
    "for i in range(len(useful_words)):\n",
    "    for word in ant_list[i]:\n",
    "        if word in raw_ant_list[i]:\n",
    "            continue\n",
    "        else:\n",
    "            raw_ant_list[i].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate DataFrame with 'useful_word' and syn/ant for each 'useful_word'\n",
    "#For each term we have a list of strings for its 'Antonyms' and 'Synonyms'\n",
    "for i in range(len(test_array_df)):\n",
    "    test_array_df.iloc[i,0] = useful_words[i]\n",
    "    test_array_df['Synonyms'].loc[i] = raw_syn_list[i]\n",
    "    test_array_df['Antonyms'].loc[i] = raw_ant_list[i]\n",
    "test_array_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ON HOLD FOR NOW\n",
    "#For WordNet\n",
    "useful_words = ['straight']\n",
    "for word in useful_words: #pull words from a premade list to query WordNet\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get('http://wordnetweb.princeton.edu/perl/webwn?s=' + word + '&sub=Search+WordNet&o2=&o0=1&o8=1&o1=1&o7=&o5=&o9=&o6=&o3=&o4=&h=000000000000000000000')\n",
    "    \n",
    "    html_doc = driver.page_source # stores the source HTML code in the driver's page_source attribute\n",
    "    soup = bs(html_doc, 'html.parser')\n",
    "    syn = soup.find('a', {'href':\"webwn?o2=&amp;o0=1&amp;o8=1&amp;o1=1&amp;o7=&amp;o5=&amp;o9=&amp;o6=&amp;o3=&amp;o4=&amp;s=\" + word + \"&amp;i=1&amp;h=00#c\"})\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "print (syn)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
