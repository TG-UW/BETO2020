{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from gensim.models import Word2Vec as wv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "#import PhysicallyInformedLossFunction as PhysLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocabulary from Carbon corpus and Word2Vec model trained on all abstracts\n",
    "#Opening contents of Word2Vec model1\n",
    "data = '/Users/Thomas/Desktop/BETO2020-master/Ant_Syn_Scraping/all_abstracts_model'\n",
    "os.chdir(data)\n",
    "model1 = wv.load('all_abstract_model.model')\n",
    "vocabulary1 = list(model1.wv.vocab)\n",
    "#use model.build_vocab(sentence, update=True) to add missing words to model's vocabulary?\n",
    "#or delete the rows that yield the KeyError?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '/Users/Thomas/Desktop/BETO2020-master/Ant_Syn_Scraping/'\n",
    "os.chdir(data)\n",
    "data_df = pd.read_excel('Carbon_SynAntList_Full_Refined_copy.xlsx', skip_rows=1, nrows=2000, index_col=0)\n",
    "data_df = data_df.rename(columns = {'Unnamed: 1':'word 1', 'Unnamed: 2':'word 2','Unnamed: 3':'relationship', 'Unnamed: 4': 'label'})\n",
    "#Adding columns for the syn and ant score labeling\n",
    "data_df['syn score'] = np.nan\n",
    "data_df['ant score'] = np.nan\n",
    "data_df = data_df.fillna(0)\n",
    "data_df = data_df[1:]\n",
    "\n",
    "#finding which words are in the pd but not in vocabulary1\n",
    "list1 = list(data_df['word 1'])\n",
    "list2 = list(data_df['word 2'])\n",
    "missing = list((set(list1).difference(vocabulary1))) + list((set(list2).difference(vocabulary1)))\n",
    "\n",
    "#keeping only the rows in the pd that have words in vocabulary1\n",
    "data_df = data_df[~data_df['word 1'].isin(missing)]\n",
    "data_df = data_df[~data_df['word 2'].isin(missing)]\n",
    "\n",
    "#reseting indeces after mask\n",
    "data_df.reset_index(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Carbon_SynAntList_Full_Refined</th>\n",
       "      <th>word 1</th>\n",
       "      <th>word 2</th>\n",
       "      <th>relationship</th>\n",
       "      <th>label</th>\n",
       "      <th>syn score</th>\n",
       "      <th>ant score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0246488, -5.6508703, -1.4263288, -3.1607409...</td>\n",
       "      <td>[0.3912109, -2.6639938, -0.4191871, -0.3595066...</td>\n",
       "      <td>syn</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[1.0246488, -5.6508703, -1.4263288, -3.1607409...</td>\n",
       "      <td>[0.67807263, -0.0778522, 3.3564792, -1.8280518...</td>\n",
       "      <td>syn</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[1.0246488, -5.6508703, -1.4263288, -3.1607409...</td>\n",
       "      <td>[-0.40175724, 0.66337395, -1.5072205, -1.73012...</td>\n",
       "      <td>syn</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[1.0246488, -5.6508703, -1.4263288, -3.1607409...</td>\n",
       "      <td>[2.6374276, -0.8799803, 1.9580756, -3.1686919,...</td>\n",
       "      <td>syn</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>[1.0246488, -5.6508703, -1.4263288, -3.1607409...</td>\n",
       "      <td>[-1.5558529, 2.824446, -3.416154, -0.963536, 0...</td>\n",
       "      <td>syn</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>[-0.2082266, 1.1971192, 1.1562068, -5.095038, ...</td>\n",
       "      <td>[-1.9820197, 0.99323726, 1.025493, -1.2684621,...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1995.0</td>\n",
       "      <td>[-0.2082266, 1.1971192, 1.1562068, -5.095038, ...</td>\n",
       "      <td>[0.38347286, 0.7061271, -0.007815216, -1.64924...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1996.0</td>\n",
       "      <td>[-0.2082266, 1.1971192, 1.1562068, -5.095038, ...</td>\n",
       "      <td>[-2.8429897, 1.9741825, -0.3001447, -5.303599,...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1997.0</td>\n",
       "      <td>[-0.2082266, 1.1971192, 1.1562068, -5.095038, ...</td>\n",
       "      <td>[0.26439202, 0.44663662, -0.2789563, -3.575421...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1998.0</td>\n",
       "      <td>[-0.2082266, 1.1971192, 1.1562068, -5.095038, ...</td>\n",
       "      <td>[-7.4225054, -2.0302646, 0.6465284, -7.604581,...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Carbon_SynAntList_Full_Refined  \\\n",
       "0                                1.0   \n",
       "1                                2.0   \n",
       "2                                3.0   \n",
       "3                                4.0   \n",
       "4                                7.0   \n",
       "...                              ...   \n",
       "1595                          1994.0   \n",
       "1596                          1995.0   \n",
       "1597                          1996.0   \n",
       "1598                          1997.0   \n",
       "1599                          1998.0   \n",
       "\n",
       "                                                 word 1  \\\n",
       "0     [1.0246488, -5.6508703, -1.4263288, -3.1607409...   \n",
       "1     [1.0246488, -5.6508703, -1.4263288, -3.1607409...   \n",
       "2     [1.0246488, -5.6508703, -1.4263288, -3.1607409...   \n",
       "3     [1.0246488, -5.6508703, -1.4263288, -3.1607409...   \n",
       "4     [1.0246488, -5.6508703, -1.4263288, -3.1607409...   \n",
       "...                                                 ...   \n",
       "1595  [-0.2082266, 1.1971192, 1.1562068, -5.095038, ...   \n",
       "1596  [-0.2082266, 1.1971192, 1.1562068, -5.095038, ...   \n",
       "1597  [-0.2082266, 1.1971192, 1.1562068, -5.095038, ...   \n",
       "1598  [-0.2082266, 1.1971192, 1.1562068, -5.095038, ...   \n",
       "1599  [-0.2082266, 1.1971192, 1.1562068, -5.095038, ...   \n",
       "\n",
       "                                                 word 2 relationship label  \\\n",
       "0     [0.3912109, -2.6639938, -0.4191871, -0.3595066...          syn     1   \n",
       "1     [0.67807263, -0.0778522, 3.3564792, -1.8280518...          syn     1   \n",
       "2     [-0.40175724, 0.66337395, -1.5072205, -1.73012...          syn     0   \n",
       "3     [2.6374276, -0.8799803, 1.9580756, -3.1686919,...          syn     0   \n",
       "4     [-1.5558529, 2.824446, -3.416154, -0.963536, 0...          syn     0   \n",
       "...                                                 ...          ...   ...   \n",
       "1595  [-1.9820197, 0.99323726, 1.025493, -1.2684621,...          ant     0   \n",
       "1596  [0.38347286, 0.7061271, -0.007815216, -1.64924...          ant     0   \n",
       "1597  [-2.8429897, 1.9741825, -0.3001447, -5.303599,...          ant     0   \n",
       "1598  [0.26439202, 0.44663662, -0.2789563, -3.575421...          ant     0   \n",
       "1599  [-7.4225054, -2.0302646, 0.6465284, -7.604581,...          ant     0   \n",
       "\n",
       "      syn score  ant score  \n",
       "0           1.0       -1.0  \n",
       "1           1.0       -1.0  \n",
       "2           0.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "...         ...        ...  \n",
       "1595        0.0        0.0  \n",
       "1596        0.0        0.0  \n",
       "1597        0.0        0.0  \n",
       "1598        0.0        0.0  \n",
       "1599        0.0        0.0  \n",
       "\n",
       "[1600 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Thomas/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_df)): \n",
    "    data_df['word 1'].iloc[i] = model1.wv.__getitem__(str(data_df['word 1'].iloc[i]))\n",
    "    data_df['word 2'].iloc[i] = model1.wv.__getitem__(str(data_df['word 2'].iloc[i]))\n",
    "    \n",
    "    if data_df['relationship'].iloc[i] == 'syn' and data_df['label'].iloc[i] == 1:\n",
    "        data_df['syn score'].iloc[i] = 1\n",
    "        data_df['ant score'].iloc[i] = -1\n",
    "       \n",
    "    elif data_df['relationship'].iloc[i] == 'ant' and data_df['label'].iloc[i] == 1:\n",
    "        data_df['syn score'].iloc[i] = -1 \n",
    "        data_df ['ant score'].iloc[i] = 1\n",
    "        \n",
    "    else:\n",
    "        data_df['syn score'].iloc[i] = 0  \n",
    "        data_df['ant score'].iloc[i] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_json('Phase_I_DATA.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_json('Phase_I_DATA.json', dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df[['word 1', 'word 2']]\n",
    "Y = data_df[['syn score', 'ant score']]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "w1_train = x_train['word 1']\n",
    "w1_test = x_test['word 1']\n",
    "w2_train = x_train['word 2']\n",
    "w2_test = x_test['word 2']\n",
    "ss_train = y_train['syn score']\n",
    "ss_test = y_test['syn score']\n",
    "as_train = y_train['ant score']\n",
    "as_test = y_test['ant score']\n",
    "\n",
    "train_data = {'word 1': w1_train, 'word 2': w2_train, 'syn score': ss_train, 'ant score': as_train}\n",
    "test_data = {'word 1': w1_test, 'word 2': w2_test, 'syn score': ss_test, 'ant score': as_test}\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_json('Phase_I_Train.json')\n",
    "test_df.to_json('Phase_I_Test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f350a1bf80e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word 1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'word 2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "data_test[['word 1','word 2']].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word 1</th>\n",
       "      <th>word 2</th>\n",
       "      <th>syn score</th>\n",
       "      <th>ant score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>[-1.0964479446, 1.8805480003000001, 7.23442029...</td>\n",
       "      <td>[-1.3677221537, -0.019086884300000002, 0.45717...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>[-2.1888554096, 0.4787855446, -0.3963083327, -...</td>\n",
       "      <td>[-0.4821321964, -0.6129127145000001, -0.523134...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>[-4.5729045868, -6.443136692, 5.7944054604, -6...</td>\n",
       "      <td>[0.0011501729, 0.07786653190000001, 0.21224316...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>[-0.9819027185, 0.8721030354, -3.6479685307, -...</td>\n",
       "      <td>[0.1252089888, 0.0357500389, 0.1065470129, -0....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>[1.9019999504, 6.5153040886, 0.9711658955, 1.0...</td>\n",
       "      <td>[-0.0920875221, 0.204548806, 0.353068590200000...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>[0.18577489260000002, 5.0477662086, 0.08229728...</td>\n",
       "      <td>[2.3581871986, 2.4673128128, -0.7351281047, -5...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>[-0.44115230440000003, 6.5217018127, -1.735963...</td>\n",
       "      <td>[-2.6894249916, 2.8726806641, -2.5519349575, -...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>[-4.5729045868, -6.443136692, 5.7944054604, -6...</td>\n",
       "      <td>[-7.3409018517, -2.5313780308, 1.9750880003, -...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>[2.9429700375000003, 3.3651957512, -3.32590603...</td>\n",
       "      <td>[-4.2139658928, 3.4794118404, -2.6765217781, 0...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>[2.2395038605, 3.5965807438, -1.2376616001, 1....</td>\n",
       "      <td>[-1.2974791527, 1.3168876171, -0.3963227272, -...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 word 1  \\\n",
       "605   [-1.0964479446, 1.8805480003000001, 7.23442029...   \n",
       "961   [-2.1888554096, 0.4787855446, -0.3963083327, -...   \n",
       "1430  [-4.5729045868, -6.443136692, 5.7944054604, -6...   \n",
       "64    [-0.9819027185, 0.8721030354, -3.6479685307, -...   \n",
       "446   [1.9019999504, 6.5153040886, 0.9711658955, 1.0...   \n",
       "...                                                 ...   \n",
       "1327  [0.18577489260000002, 5.0477662086, 0.08229728...   \n",
       "1263  [-0.44115230440000003, 6.5217018127, -1.735963...   \n",
       "1420  [-4.5729045868, -6.443136692, 5.7944054604, -6...   \n",
       "790   [2.9429700375000003, 3.3651957512, -3.32590603...   \n",
       "848   [2.2395038605, 3.5965807438, -1.2376616001, 1....   \n",
       "\n",
       "                                                 word 2  syn score  ant score  \n",
       "605   [-1.3677221537, -0.019086884300000002, 0.45717...        1.0       -1.0  \n",
       "961   [-0.4821321964, -0.6129127145000001, -0.523134...        1.0       -1.0  \n",
       "1430  [0.0011501729, 0.07786653190000001, 0.21224316...        0.0        0.0  \n",
       "64    [0.1252089888, 0.0357500389, 0.1065470129, -0....        1.0       -1.0  \n",
       "446   [-0.0920875221, 0.204548806, 0.353068590200000...        0.0        0.0  \n",
       "...                                                 ...        ...        ...  \n",
       "1327  [2.3581871986, 2.4673128128, -0.7351281047, -5...        0.0        0.0  \n",
       "1263  [-2.6894249916, 2.8726806641, -2.5519349575, -...        0.0        0.0  \n",
       "1420  [-7.3409018517, -2.5313780308, 1.9750880003, -...        0.0        0.0  \n",
       "790   [-4.2139658928, 3.4794118404, -2.6765217781, 0...        0.0        0.0  \n",
       "848   [-1.2974791527, 1.3168876171, -0.3963227272, -...        0.0        0.0  \n",
       "\n",
       "[1280 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_json('Phase_I_Train.json', dtype = np.float32)\n",
    "data_test.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.09644794e+00,  1.88054800e+00,  7.23442030e+00, ...,\n",
       "         -1.78487390e-01,  3.47584724e+00,  4.74188423e+00],\n",
       "        [-1.36772215e+00, -1.90868843e-02,  4.57179457e-01, ...,\n",
       "         -3.98191623e-02,  1.12433410e+00,  2.05543622e-01]],\n",
       "\n",
       "       [[-2.18885541e+00,  4.78785545e-01, -3.96308333e-01, ...,\n",
       "          1.25908542e+00,  3.03345025e-01,  2.30789113e+00],\n",
       "        [-4.82132196e-01, -6.12912715e-01, -5.23134172e-01, ...,\n",
       "         -7.88991034e-01, -7.61382461e-01,  7.21247256e-01]],\n",
       "\n",
       "       [[-4.57290459e+00, -6.44313669e+00,  5.79440546e+00, ...,\n",
       "          3.90708256e+00, -2.60906339e+00,  8.76600265e+00],\n",
       "        [ 1.15017290e-03,  7.78665319e-02,  2.12243169e-01, ...,\n",
       "          2.03877643e-01,  1.32272854e-01,  7.95163587e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-4.57290459e+00, -6.44313669e+00,  5.79440546e+00, ...,\n",
       "          3.90708256e+00, -2.60906339e+00,  8.76600265e+00],\n",
       "        [-7.34090185e+00, -2.53137803e+00,  1.97508800e+00, ...,\n",
       "          3.88094306e+00,  3.46689296e+00,  4.33405685e+00]],\n",
       "\n",
       "       [[ 2.94297004e+00,  3.36519575e+00, -3.32590604e+00, ...,\n",
       "         -4.21685696e+00,  7.01191127e-01,  4.55394983e+00],\n",
       "        [-4.21396589e+00,  3.47941184e+00, -2.67652178e+00, ...,\n",
       "         -6.37274206e-01,  2.60106027e-01,  6.59690380e+00]],\n",
       "\n",
       "       [[ 2.23950386e+00,  3.59658074e+00, -1.23766160e+00, ...,\n",
       "          1.18193758e+00,  3.55653715e+00,  5.75207806e+00],\n",
       "        [-1.29747915e+00,  1.31688762e+00, -3.96322727e-01, ...,\n",
       "         -3.54636550e+00,  5.06131291e-01,  6.35391772e-01]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test1 = [[] for i in range(1280)]\n",
    "for i in range(len(data_test1)):\n",
    "    data_test1[i] = data_test[['word 1','word 2']].values[i][0],data_test[['word 1','word 2']].values[i][1]\n",
    "data_test1 = np.array(data_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "num_epochs = 100\n",
    "batch_size = 50\n",
    "learning_rate = 0.008\n",
    "\n",
    "# Device configuration (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phase_I_Train_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        data = pd.read_json('Phase_I_Train.json', dtype = np.float32)\n",
    "        self.len = data.shape[0]\n",
    "        \n",
    "        data_x = [[] for i in range(1280)] #creating empty lists to store our w1,w2 vectors in data_x and synscore,antscore in data_y\n",
    "        data_y = [[] fro i in range(1280)] #these lists are filled with data, turned into np.arrays and then to tensors\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            data_x[i] = data[['word 1','word 2']].values[i][0],data[['word 1','word 2']].values[i][1]\n",
    "        \n",
    "        data_x = np.array(data_x)\n",
    "       \n",
    "         for i in range(len(data)):\n",
    "            data_y[i] = data_test[['syn score','ant score']].values[i][0],data[['syn score','ant score']].values[i][1]\n",
    "        \n",
    "        data_y = np.array(data_y)\n",
    "            \n",
    "        #split into x_data our features and y_data our targets\n",
    "        self.x_data = torch.from_numpy(data_x)\n",
    "        self.y_data = torch.from_numpy(data_y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.x_data, self.y_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = Phase_I_Train_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phase_I_Test_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        data = pd.read_json('Phase_I_Test.json', dtype = np.float32)\n",
    "        self.len = data.shape[0]\n",
    "        \n",
    "        data_x = [[] for i in range(1280)] #creating empty lists to store our w1,w2 vectors in data_x and synscore,antscore in data_y\n",
    "        data_y = [[] fro i in range(1280)] #these lists are filled with data, turned into np.arrays and then to tensors\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            data_x[i] = data[['word 1','word 2']].values[i][0],data[['word 1','word 2']].values[i][1]\n",
    "        \n",
    "        data_x = np.array(data_x)\n",
    "       \n",
    "         for i in range(len(data)):\n",
    "            data_y[i] = data_test[['syn score','ant score']].values[i][0],data[['syn score','ant score']].values[i][1]\n",
    "        \n",
    "        data_y = np.array(data_y)\n",
    "            \n",
    "        #split into x_data our features and y_data our targets\n",
    "        self.x_data = torch.from_numpy(data_x)\n",
    "        self.y_data = torch.from_numpy(data_y)\n",
    "\n",
    "      \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = Phase_I_Test_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phase_I_NN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dims, out_dims):\n",
    "        super(SYN_TEST, self).__init__()\n",
    "        \n",
    "        #nn.Embedding.from_pretrained(weights) something to think about. weights = model1.wv.\n",
    "        \n",
    "        #hidden layers\n",
    "        self.hidden_layer = nn.Linear(100, 32)\n",
    "        self.hidden_layer1 = nn.Linear(32, 16)\n",
    "        \n",
    "        self.S_branch = nn.Sequential( #synonym subspace branch\n",
    "        nn.Linear(in_dims,50) . #nn.Embedding should have vocab_size(1280),vector_size(50)\n",
    "        nn.Dropout(0.2), #to limit overfitting\n",
    "        nn.Linear(50,100), #expand\n",
    "        nn.Linear(100,300),\n",
    "        nn.Linear(300,100),\n",
    "        nn.Linear(100,50)) #compress\n",
    "        \n",
    "        #nn.Softplus()\n",
    "        \n",
    "        self.A_branch = nn.Sequential(\n",
    "        nn.Linear(in_dims, 50)\n",
    "        nn.Dropout(0.2), #to limit overfitting\n",
    "        nn.Linear(50,100), #expand\n",
    "        nn.Linear(100,300),\n",
    "        nn.Linear(300,100),\n",
    "        nn.Linear(100,50)) #compress\n",
    "    \n",
    "   \n",
    "    def forward(self, w1, x2):\n",
    "       \n",
    "        #pass through hidden layers\n",
    "        w1 = self.hidden_layer(w1)\n",
    "        w1 = self.hidden1_layer(w1)\n",
    "        w2 = self.hidden_layer(w2)\n",
    "        w2 = self.hidden_layer1(w2)\n",
    "        \n",
    "        #pass each embedded data through each branch to be situated in subspaces\n",
    "        S1_out = self.S_branch(w1)\n",
    "        S2_out = self.S_branch(w2)\n",
    "        A1_out = self.A_branch(w1)\n",
    "        A2_out = self.A_branch(w2)\n",
    "        \n",
    "        return S1_out, A1_out, S2_out, A2_out #the encoders in each subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
