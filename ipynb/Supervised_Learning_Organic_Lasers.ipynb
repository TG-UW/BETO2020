{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "\n",
    "def extractor(url,wait_time):\n",
    "    \"\"\"\n",
    "    Accepts a url and stores its html code before parsing and extracting the abstract as text.\n",
    "    Feeds directly into parser, so don't call this function unless you want to obtain the abstract\n",
    "    from a single url.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    #driver.find_element_by_id('').send_keys('')#\n",
    "    #driver.find_element_by_id ('').send_keys('')#\n",
    "    #driver.find_element_by_id('submit').click()#\n",
    "    time.sleep(wait_time) # important\n",
    "\n",
    "    html_doc = driver.page_source # stores the source HTML code in the driver's page_source attribute\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    abstract = soup.find('div', {'class':\"abstract author\"}).find('p').text\n",
    "    \n",
    "    driver.quit()\n",
    "    return abstract\n",
    "\n",
    "def parse_all(driver):\n",
    "    \"\"\"\n",
    "    The following method is designed to automatically parse each url contained in a long list \n",
    "    of scraped urls, and writes the title, abstract, and doi to a new text file with a user\n",
    "    input \"file_name.txt.\"\n",
    "    \"\"\"\n",
    "    url_lst = input(\"Enter name of file with .txt extension with list of urls: \")\n",
    "    data = pd.read_csv(url_lst,header=None,names=['url']) #text file containing a list of the scraped urls (should be in same directory)\n",
    "    file_name = input(\"Input the file name with .txt extension you wish to store abstracts in: \")\n",
    "    file = open(file_name,'w')\n",
    "\n",
    "    max_iters = len(data) #total number of scraped urls to be parsed\n",
    "    print(\"The parser will parse: \" + str(max_iters) + \" urls.\")\n",
    "\n",
    "    for i in range(0,max_iters):\n",
    "        print('On url ',i)\n",
    "        driver.refresh()\n",
    "        time.sleep(2)\n",
    "        urli = str(extractor(data.iloc[i,0],3))\n",
    "        file.write(urli)\n",
    "        file.write('\\n')\n",
    "    driver.quit()\n",
    "\n",
    "    return file_name\n",
    "\n",
    "### Actual executable code is shown below ###\n",
    "### driver = webdriver.Chrome()\n",
    "### parse_all(driver)\n",
    "\n",
    "def tokenizer(file_name):\n",
    "    \"\"\" \n",
    "    Accepts text file as a string (e.g. \"abstracts.txt\") containing a list of abstracts as input and cleans up text using regex.\n",
    "    \"\"\"\n",
    "    with open(file_name) as file:\n",
    "        corpus = file.readlines()\n",
    "        processed_abstracts = [w.lower() for w in corpus]\n",
    "        processed_abstracts = [re.sub('[^a-zA-Z]', ' ', w) for w in processed_abstracts]\n",
    "        processed_abstracts = [re.sub(r'\\s+', ' ', w) for w in processed_abstracts]\n",
    "    tokens = [nltk.word_tokenize(sent) for sent in processed_abstracts]\n",
    "\n",
    "    for i in range(len(processed_abstracts)):\n",
    "        tokens[i] = [w for w in tokens[i] if w not in stopwords.words('english')]\n",
    "\n",
    "    # Passes all tokens to Word2Vec to train model\n",
    "    model = Word2Vec(tokens, size=100, min_count=2, iter=10) \n",
    "    vocabulary = model.wv.vocab\n",
    "\n",
    "    return model, vocabulary\n",
    "\n",
    "def single_abstract_tkzr(url,wait_time):\n",
    "    \"\"\"\n",
    "    This method tokenizes an abstract from a single url. Wait time is an integer number of seconds you\n",
    "    want to wait for the page to load.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    abstract_text = extractor(url,wait_time)\n",
    "    test_abstract = abstract_text.lower()\n",
    "    test_abstract = re.sub('[^a-zA-Z]', ' ', test_abstract) \n",
    "    test_abstract = re.sub(r'\\s+', ' ', test_abstract)\n",
    "        \n",
    "    abstract_tokens = nltk.word_tokenize(test_abstract)\n",
    "\n",
    "    text_tokens = [tkn for tkn in abstract_tokens if tkn not in stopwords.words('english')]\n",
    "    driver.quit()\n",
    "    return text_tokens\n",
    "\n",
    "def cosine_scores(search_terms,text_tokens,model,n_tokens):\n",
    "    \"\"\"\n",
    "    Extracts the top n most similar tokens and their respective cosine similarity scores by \n",
    "    comparing the tokens from a single abstract to the trained vocabulary.\n",
    "    Parameters:\n",
    "    search_terms: desired search terms written as a list of strings; \n",
    "    text_tokens: A list of tokens for the text_tokens;\n",
    "    model: The trained word2vec model;\n",
    "    n_tokens: the number of top most similar tokens you'd like to return\n",
    "    \"\"\"\n",
    "\n",
    "    store = defaultdict(int)\n",
    "    for word in search_terms:\n",
    "        for tkn in text_tokens:\n",
    "            store[tkn] += model.wv.similarity(word,tkn)\n",
    "    \n",
    "    # Orders dictionary from highest to lowest cosine similarity score\n",
    "    cos_scores = sorted(store.items() , reverse=True, key=lambda x: x[1])\n",
    "    \n",
    "    # Extracts top 20 most similar tokens\n",
    "    return cos_scores[:int(n_tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On url 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Thomas/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On url 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Thomas/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On url 2\n",
      "                                                    URL  \\\n",
      "0     https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1     https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "2     https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "3     https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "4     https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "5     https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "6     https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "7     https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "8     https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "9     https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "10    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "11    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "13    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "15    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "16    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "17    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "18    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "19    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "20    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "21    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "22    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "23    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "24    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "25    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "26    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "27    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "28    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "29    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "30    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "31    https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "...                                                 ...   \n",
      "1212  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1213  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1214  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1215  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1216  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1217  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1218  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1219  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1220  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1221  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1222  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1223  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1224  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1225  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1226  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1227  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1228  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1229  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1230  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1231  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1233  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1234  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1235  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1236  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1237  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1239  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1240  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1241  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1242  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "1243  https://www-sciencedirect-com.offcampus.lib.wa...   \n",
      "\n",
      "                                               Abstract  Tokens  \\\n",
      "0     <div class=\"Abstracts u-font-serif\" id=\"abstra...     NaN   \n",
      "1     <div class=\"Abstracts u-font-serif\" id=\"abstra...     NaN   \n",
      "2     <div class=\"Abstracts u-font-serif\" id=\"abstra...     NaN   \n",
      "3                                                   NaN     NaN   \n",
      "4                                                   NaN     NaN   \n",
      "5                                                   NaN     NaN   \n",
      "6                                                   NaN     NaN   \n",
      "7                                                   NaN     NaN   \n",
      "8                                                   NaN     NaN   \n",
      "9                                                   NaN     NaN   \n",
      "10                                                  NaN     NaN   \n",
      "11                                                  NaN     NaN   \n",
      "13                                                  NaN     NaN   \n",
      "15                                                  NaN     NaN   \n",
      "16                                                  NaN     NaN   \n",
      "17                                                  NaN     NaN   \n",
      "18                                                  NaN     NaN   \n",
      "19                                                  NaN     NaN   \n",
      "20                                                  NaN     NaN   \n",
      "21                                                  NaN     NaN   \n",
      "22                                                  NaN     NaN   \n",
      "23                                                  NaN     NaN   \n",
      "24                                                  NaN     NaN   \n",
      "25                                                  NaN     NaN   \n",
      "26                                                  NaN     NaN   \n",
      "27                                                  NaN     NaN   \n",
      "28                                                  NaN     NaN   \n",
      "29                                                  NaN     NaN   \n",
      "30                                                  NaN     NaN   \n",
      "31                                                  NaN     NaN   \n",
      "...                                                 ...     ...   \n",
      "1212                                                NaN     NaN   \n",
      "1213                                                NaN     NaN   \n",
      "1214                                                NaN     NaN   \n",
      "1215                                                NaN     NaN   \n",
      "1216                                                NaN     NaN   \n",
      "1217                                                NaN     NaN   \n",
      "1218                                                NaN     NaN   \n",
      "1219                                                NaN     NaN   \n",
      "1220                                                NaN     NaN   \n",
      "1221                                                NaN     NaN   \n",
      "1222                                                NaN     NaN   \n",
      "1223                                                NaN     NaN   \n",
      "1224                                                NaN     NaN   \n",
      "1225                                                NaN     NaN   \n",
      "1226                                                NaN     NaN   \n",
      "1227                                                NaN     NaN   \n",
      "1228                                                NaN     NaN   \n",
      "1229                                                NaN     NaN   \n",
      "1230                                                NaN     NaN   \n",
      "1231                                                NaN     NaN   \n",
      "1233                                                NaN     NaN   \n",
      "1234                                                NaN     NaN   \n",
      "1235                                                NaN     NaN   \n",
      "1236                                                NaN     NaN   \n",
      "1237                                                NaN     NaN   \n",
      "1239                                                NaN     NaN   \n",
      "1240                                                NaN     NaN   \n",
      "1241                                                NaN     NaN   \n",
      "1242                                                NaN     NaN   \n",
      "1243                                                NaN     NaN   \n",
      "\n",
      "      Cosine Top 20  Cumulative Sum  Score AC  Score TG  Score WT  \n",
      "0               NaN             NaN       1.0       NaN       NaN  \n",
      "1               NaN             NaN       2.0       NaN       NaN  \n",
      "2               NaN             NaN       1.0       NaN       NaN  \n",
      "3               NaN             NaN       1.0       NaN       NaN  \n",
      "4               NaN             NaN       2.0       NaN       NaN  \n",
      "5               NaN             NaN       0.0       NaN       NaN  \n",
      "6               NaN             NaN       0.0       NaN       NaN  \n",
      "7               NaN             NaN       0.0       NaN       NaN  \n",
      "8               NaN             NaN       0.0       NaN       NaN  \n",
      "9               NaN             NaN       0.0       NaN       NaN  \n",
      "10              NaN             NaN       0.0       NaN       NaN  \n",
      "11              NaN             NaN       0.0       NaN       NaN  \n",
      "13              NaN             NaN       0.0       NaN       NaN  \n",
      "15              NaN             NaN       0.0       NaN       NaN  \n",
      "16              NaN             NaN       1.0       NaN       NaN  \n",
      "17              NaN             NaN       2.0       NaN       NaN  \n",
      "18              NaN             NaN       0.0       NaN       NaN  \n",
      "19              NaN             NaN       2.0       NaN       NaN  \n",
      "20              NaN             NaN       1.0       NaN       NaN  \n",
      "21              NaN             NaN       2.0       NaN       NaN  \n",
      "22              NaN             NaN       0.0       NaN       NaN  \n",
      "23              NaN             NaN       0.0       NaN       NaN  \n",
      "24              NaN             NaN       0.0       NaN       NaN  \n",
      "25              NaN             NaN       0.0       NaN       NaN  \n",
      "26              NaN             NaN       0.0       NaN       NaN  \n",
      "27              NaN             NaN       0.0       NaN       NaN  \n",
      "28              NaN             NaN       0.0       NaN       NaN  \n",
      "29              NaN             NaN       0.0       NaN       NaN  \n",
      "30              NaN             NaN       0.0       NaN       NaN  \n",
      "31              NaN             NaN       0.0       NaN       NaN  \n",
      "...             ...             ...       ...       ...       ...  \n",
      "1212            NaN             NaN       NaN       NaN       0.0  \n",
      "1213            NaN             NaN       NaN       NaN       0.0  \n",
      "1214            NaN             NaN       NaN       NaN       0.0  \n",
      "1215            NaN             NaN       NaN       NaN       0.0  \n",
      "1216            NaN             NaN       NaN       NaN       0.0  \n",
      "1217            NaN             NaN       NaN       NaN       0.0  \n",
      "1218            NaN             NaN       NaN       NaN       2.0  \n",
      "1219            NaN             NaN       NaN       NaN       0.0  \n",
      "1220            NaN             NaN       NaN       NaN       0.0  \n",
      "1221            NaN             NaN       NaN       NaN       0.0  \n",
      "1222            NaN             NaN       NaN       NaN       0.0  \n",
      "1223            NaN             NaN       NaN       NaN       0.0  \n",
      "1224            NaN             NaN       NaN       NaN       0.0  \n",
      "1225            NaN             NaN       NaN       NaN       0.0  \n",
      "1226            NaN             NaN       NaN       NaN       0.0  \n",
      "1227            NaN             NaN       NaN       NaN       1.0  \n",
      "1228            NaN             NaN       NaN       NaN       0.0  \n",
      "1229            NaN             NaN       NaN       NaN       0.0  \n",
      "1230            NaN             NaN       NaN       NaN       0.0  \n",
      "1231            NaN             NaN       0.0       NaN       0.0  \n",
      "1233            NaN             NaN       NaN       NaN       0.0  \n",
      "1234            NaN             NaN       NaN       NaN       0.0  \n",
      "1235            NaN             NaN       NaN       NaN       0.0  \n",
      "1236            NaN             NaN       NaN       NaN       0.0  \n",
      "1237            NaN             NaN       NaN       NaN       0.0  \n",
      "1239            NaN             NaN       NaN       NaN       1.0  \n",
      "1240            NaN             NaN       NaN       NaN       0.0  \n",
      "1241            NaN             NaN       NaN       NaN       1.0  \n",
      "1242            NaN             NaN       NaN       NaN       0.0  \n",
      "1243            NaN             NaN       NaN       NaN       0.0  \n",
      "\n",
      "[1199 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Thomas/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"organic.laser.url.csv\")\n",
    "\n",
    "#df.loc[df['PDF only'] == 0, 'PDF only'] = 'Nan'; for changing the values of 'PDF only' from 0 to 'NaN'#\n",
    "\n",
    "first_condition = df['PDF only'] == 0.0\n",
    "second_condition = df['Score AC'] >= 0.0 \n",
    "third_condition = df['Score TG'] >= 0.0\n",
    "fourth_condition = df['Score WT'] >= 0.0\n",
    "msk = (first_condition & (second_condition | third_condition | fourth_condition ))\n",
    "\n",
    "new_df = df[msk]\n",
    "new_df = new_df.reindex(columns = ['URL', 'Abstract', 'Tokens', 'Cosine Top 20', 'Cumulative Sum', 'Score AC', 'Score TG', 'Score WT'])\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "for i in range(0, 3):\n",
    "    print('On url', i)\n",
    "    driver.refresh()\n",
    "    time.sleep(2)\n",
    "    new_df['Abstract'].iloc[i] = str(extractor(new_df['URL'].iloc[i],3))\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "#Need to save new_df and abstracts.txt\n",
    "\n",
    "print (new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction of microstructures into an organic light-emitting device (OLED) is being considered as an effective approach to outcouple photons trapped in waveguide (WG) and surface plasmon-polariton (SPP) modes within the devices. However, the attempt has been hampered by the difficulty in applying lithographic patterning technologies on organic materials. Here, we show the end has been simply reached by one-step directly laser ablating the hole-transporting layer of the OLEDs without inducing any optical or electrical deterioration. Three times efficiency enhancement has been experimentally attained from the corrugated OLEDs, which has then been ascribed by numerical simulation to the efficient outcoupling of the SPP and WG modes to radiation.\n"
     ]
    }
   ],
   "source": [
    "test_url = 'https://www-sciencedirect-com.offcampus.lib.washington.edu/science/article/pii/S1566119911002801'\n",
    "\n",
    "print(str(extractor(test_url, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('Organic_Laser_Abstracts.csv')\n",
    "new_df['Abstracts'].to_txt('Organic_Laser_Tokenizer.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have tokens added to the new_df and teach Word2Vec model#\n",
    "\n",
    "txt_abstracts = pd.read_txt('.txt')\n",
    "new_df = pd.read_csv('.csv')\n",
    "\n",
    "for i in range(0,len(new_df)):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year                                                URL  Score AC  \\\n",
      "0     2011  https://www-sciencedirect-com.offcampus.lib.wa...       1.0   \n",
      "1     2011  https://www-sciencedirect-com.offcampus.lib.wa...       2.0   \n",
      "2     2011  https://www-sciencedirect-com.offcampus.lib.wa...       1.0   \n",
      "3     2011  https://www-sciencedirect-com.offcampus.lib.wa...       1.0   \n",
      "4     2011  https://www-sciencedirect-com.offcampus.lib.wa...       2.0   \n",
      "5     2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "6     2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "7     2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "8     2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "9     2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "10    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "11    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "12    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "13    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "14    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "15    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "16    2011  https://www-sciencedirect-com.offcampus.lib.wa...       1.0   \n",
      "17    2011  https://www-sciencedirect-com.offcampus.lib.wa...       2.0   \n",
      "18    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "19    2011  https://www-sciencedirect-com.offcampus.lib.wa...       2.0   \n",
      "20    2011  https://www-sciencedirect-com.offcampus.lib.wa...       1.0   \n",
      "21    2011  https://www-sciencedirect-com.offcampus.lib.wa...       2.0   \n",
      "22    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "23    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "24    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "25    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "26    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "27    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "28    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "29    2011  https://www-sciencedirect-com.offcampus.lib.wa...       0.0   \n",
      "...    ...                                                ...       ...   \n",
      "1473  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1474  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1475  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1476  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1477  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1478  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1479  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1480  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1481  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1482  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1483  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1484  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1485  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1486  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1487  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1488  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1489  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1490  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1491  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1492  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1493  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1494  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1495  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1496  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1497  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1498  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1499  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1500  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1501  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "1502  2019  https://www-sciencedirect-com.offcampus.lib.wa...       NaN   \n",
      "\n",
      "      Score TG  Score WT  PDF only  Unnamed: 6  \n",
      "0          NaN       NaN       0.0         NaN  \n",
      "1          NaN       NaN       0.0         NaN  \n",
      "2          NaN       NaN       0.0         NaN  \n",
      "3          NaN       NaN       0.0         NaN  \n",
      "4          NaN       NaN       0.0         NaN  \n",
      "5          NaN       NaN       0.0         NaN  \n",
      "6          NaN       NaN       0.0         NaN  \n",
      "7          NaN       NaN       0.0         NaN  \n",
      "8          NaN       NaN       0.0         NaN  \n",
      "9          NaN       NaN       0.0         NaN  \n",
      "10         NaN       NaN       0.0         NaN  \n",
      "11         NaN       NaN       0.0         NaN  \n",
      "12         NaN       NaN       1.0         NaN  \n",
      "13         NaN       NaN       0.0         NaN  \n",
      "14         NaN       NaN       1.0         NaN  \n",
      "15         NaN       NaN       0.0         NaN  \n",
      "16         NaN       NaN       0.0         NaN  \n",
      "17         NaN       NaN       0.0         NaN  \n",
      "18         NaN       NaN       0.0         NaN  \n",
      "19         NaN       NaN       0.0         NaN  \n",
      "20         NaN       NaN       0.0         NaN  \n",
      "21         NaN       NaN       0.0         NaN  \n",
      "22         NaN       NaN       0.0         NaN  \n",
      "23         NaN       NaN       0.0         NaN  \n",
      "24         NaN       NaN       0.0         NaN  \n",
      "25         NaN       NaN       0.0         NaN  \n",
      "26         NaN       NaN       0.0         NaN  \n",
      "27         NaN       NaN       0.0         NaN  \n",
      "28         NaN       NaN       0.0         NaN  \n",
      "29         NaN       NaN       0.0         NaN  \n",
      "...        ...       ...       ...         ...  \n",
      "1473       NaN       NaN       NaN         NaN  \n",
      "1474       NaN       NaN       NaN         NaN  \n",
      "1475       NaN       NaN       NaN         NaN  \n",
      "1476       NaN       NaN       NaN         NaN  \n",
      "1477       NaN       NaN       NaN         NaN  \n",
      "1478       NaN       NaN       NaN         NaN  \n",
      "1479       NaN       NaN       NaN         NaN  \n",
      "1480       NaN       NaN       NaN         NaN  \n",
      "1481       NaN       NaN       NaN         NaN  \n",
      "1482       NaN       NaN       NaN         NaN  \n",
      "1483       NaN       NaN       NaN         NaN  \n",
      "1484       NaN       NaN       NaN         NaN  \n",
      "1485       NaN       NaN       NaN         NaN  \n",
      "1486       NaN       NaN       NaN         NaN  \n",
      "1487       NaN       NaN       NaN         NaN  \n",
      "1488       NaN       NaN       NaN         NaN  \n",
      "1489       NaN       NaN       NaN         NaN  \n",
      "1490       NaN       NaN       NaN         NaN  \n",
      "1491       NaN       NaN       NaN         NaN  \n",
      "1492       NaN       NaN       NaN         NaN  \n",
      "1493       NaN       NaN       NaN         NaN  \n",
      "1494       NaN       NaN       NaN         NaN  \n",
      "1495       NaN       NaN       NaN         NaN  \n",
      "1496       NaN       NaN       NaN         NaN  \n",
      "1497       NaN       NaN       NaN         NaN  \n",
      "1498       NaN       NaN       NaN         NaN  \n",
      "1499       NaN       NaN       NaN         NaN  \n",
      "1500       NaN       NaN       NaN         NaN  \n",
      "1501       NaN       NaN       NaN         NaN  \n",
      "1502       NaN       NaN       NaN         NaN  \n",
      "\n",
      "[1503 rows x 7 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
